from openai import OpenAI
import streamlit as st
import os

# Optional: Uncomment if you later use LangChain features again
# from langchain_community.chat_models import ChatOpenAI
# from langchain_community.callbacks.streamlit import StreamlitCallbackHandler

# Load API key from environment or sidebar input
openai_api_key = os.getenv("OPENAI_API_KEY")

with st.sidebar:
    if not openai_api_key:
        openai_api_key = st.text_input("ğŸ”‘ OpenAI API Key", key="chatbot_api_key", type="password")
    st.markdown("[Get an OpenAI API key](https://platform.openai.com/account/api-keys)")
    st.markdown("[View the source code](https://github.com/streamlit/llm-examples/blob/main/Chatbot.py)")
    st.markdown("[![Open in GitHub Codespaces](https://github.com/codespaces/badge.svg)](https://codespaces.new/streamlit/llm-examples?quickstart=1)")

st.title("ğŸ’¬ Chatbot")
st.caption("ğŸš€ A Streamlit chatbot powered by OpenAI")

# Initialize chat history
if "messages" not in st.session_state:
    st.session_state["messages"] = [{"role": "assistant", "content": "How can I help you?"}]

# Display chat history
for msg in st.session_state.messages:
    st.chat_message(msg["role"]).write(msg["content"])

# Handle user input
if prompt := st.chat_input():
    if not openai_api_key:
        st.info("Please add your OpenAI API key to continue.")
        st.stop()

    # Initialize OpenAI client
    client = OpenAI(api_key=openai_api_key)

    # Append user message
    st.session_state.messages.append({"role": "user", "content": prompt})
    st.chat_message("user").write(prompt)

    # Get assistant response
    try:
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=st.session_state.messages,
        )
        msg = response.choices[0].message.content
    except Exception as e:
        msg = f"âŒ Error: {str(e)}"

    # Append assistant response
    st.session_state.messages.append({"role": "assistant", "content": msg})
    st.chat_message("assistant").write(msg)
